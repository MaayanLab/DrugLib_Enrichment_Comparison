---
title: "Comparing drug target libraries using enrichment analysis"
author: "Damon Pham"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
#source("https://bioconductor.org/biocLite.R")
#biocLite("biomaRt")
#biocLite("rhdf5")
#biocLite("UniProt.ws")
#devtools::install_github("cmap/cmapR")

list.of.packages <- c('kableExtra', 'knitr', 'ggplot2', 'cmapR', 'stringi', 'data.table','gridExtra','reshape2','grid', 'biomaRt', 'webchem', 'httr', 'jsonlite','UniProt.ws', 'magrittr', 'VennDiagram')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list.of.packages, new.packages)

opts_chunk$set(echo=FALSE, cache=TRUE, autodep=TRUE, eval=FALSE,
               message=FALSE, warning=FALSE,
               fig.align="center")

source('writeup_scripts.R')
```

## Project description

In this project, I evaluated the accuracy of different drug target libraries by measuring their agreement with drug perturbation signature libraries. The drug target libraries I looked at are DrugBank, the Target Central Resource Database, the Drug Repurposing Hub, the Drug Gene Interaction Database (DGIdb), DrugCentral, STITCH, and the Drug Target Commons. The drug perturbation signature libraries I used are the CRowd Extracted Expression of Differential Signatures (CREEDS) and the LINCS L1000. For all drug target libraries, since their average number of gene targets was small, I used hu.MAP and ARCHS4, protein-protein interaction (PPI) databases, and ARCHS4, a protein co-expression database, to create expanded gene sets from the target lists.

I measured agreement using enrichment analysis--specifically, the Fisher's exact test for overrepresentation. I treated each (drug, expanded target list) from the drug target libraries as an (annotation, gene set) pair, and each (drug sample, list of most-perturbed genes) from the drug perturbation signature libraries also as an (annotation, gene set) pair. I then performed enrichment into one library using the gene sets from the other library, and observed how highly the matching annotations, i.e. those which correspond to the same drug as the input, were ranked. If two libraries agree with one another, then these matching annotations should often be highly ranked.

## Setup

In order to perform enrichment analysis, I needed to do two things:

1. Convert all libraries to gene vector matrix (gvm) format. In this format, each drug annotation is a column label, and each gene, represented by its HGNC symbol, is a row label. Cell values are TRUE or FALSE depending on whether the column annotation is associated with the row gene. For completeness, I also obtained gmt files for each of the libraries.

2. Identify matching annotations, i.e. drug synonyms, among the libraries. I accomplished this by renaming annotations to their corresponding drug's PubChem Compound ID. This was performed by accessing PubChem's synonym database through the webchem R package. If the PubChem Compound ID was not available, I instead used the drug's lowest alphabetical synonym, with alphanumeric characters only, and all letters in lowercase. 

* In the future, I might also access the Chemical Translation Service through webchem to recover any IDs PubChem was able to obtain.

These steps are described below, for each library. 

#### DrugBank, TCRD, DrugRepHub, DGIdb, and DrugCentral

These five drug target libraries have a name and ChEMBL ID (always present), as well as a DrugBank ID (sometimes missing) for each drug. I began by aggregating all drugs across these libraries. Then, I tried to obtain the PubChem IDs by using, in this order:

* the ChEMBL ID
* the Drug Name
* the DrugBank ID
* the SMILES
* the cleaned Drug Name (alphanumeric characters only)

```{r five_dtarget_libs, eval = TRUE}
fivedtlibs_fnames = c(
  'original_drug-gene_libs/1_DrugBank_Column_5OrMoreTargets_MissingChEMBL_IDsRemoved_1-14-18.csv',
  'original_drug-gene_libs/2_TargetCentral_Column_5OrMoreTargets_MissingChEMBL_IDsRemoved_1-14-18.csv',
  'original_drug-gene_libs/4_DGIdb_Column_5OrMoreTargets_MissingChEMBL_IDsRemoved_1-14-18.csv',
  'original_drug-gene_libs/3_RepurposeHub_Column_5OrMoreTargets_MissingChEMBL_IDsRemoved_1-14-18.csv',
  'original_drug-gene_libs/5b_DrugCentral_Column_5OrMoreTargets_MissingChEMBL_IDsRemoved_Human_1-14-18.csv'
)
fivedtlibs_libnames = c('DrugBank','TargetCentral','DGIdb','RepurposeHub','DrugCentral')
```

```{r five_dtargetlibs_check_for_invalid_ChEMBL_IDs, eval=FALSE}
#To check for invalid ChEMBL IDs, I viewed all IDs with (1) any punctuation including spaces, or (2) without the "chembl" substring. 
#There weren't any, so I did not include this check in my report.

all_ChEMBL_IDs = vector(mode='list', length=5)
for(i in 1:length(fivedtlibs_fnames)){
  lib = fread(fivedtlibs_fnames[[i]])
  all_ChEMBL_IDs[[i]] =unique(lib$DrugID_ChEMBL)
}
all_ChEMBL_IDs = unique(tolower(unlist(all_ChEMBL_IDs)))
invalid_ChEMBL_IDs = all_ChEMBL_IDs[grepl('[^[:alnum:]]',all_ChEMBL_IDs) | !(grepl('chembl',all_ChEMBL_IDs))]
knitr::kable(matrix(invalid_ChEMBL_IDs, ncol=3), 'html', caption='Invalid ChEMBL IDs') %>%
  kable_styling(bootstrap_options=c('striped', 'condensed', full_width=F, font_size=10))
rm(all_ChEMBL_IDs, invalid_ChEMBL_IDs, lib)
```

```{r five_dtargetlibs_aggregate_drugs, eval = TRUE}
fivedtlibs_identifiers = matrix(NA, nrow=4, ncol=0)
for(i in 1:length(fivedtlibs_fnames)){
  lib = fread(fivedtlibs_fnames[[i]])
  #I manually renamed the 'DrugSMILES' or 'SMILES' column to 'DrugID_SMILES' for some of the libraries.
  lib = lib[,c('DrugName','DrugID_ChEMBL','DrugID_DrugBank','DrugID_SMILES')]
  lib = unique(as.data.frame(sapply(lib, tolower)))
  fivedtlibs_identifiers = unique(rbind(fivedtlibs_identifiers, lib))
}

#Keep only the first entry for all unique ChEMBL IDs.
fivedtlibs_identifiers = fivedtlibs_identifiers[!duplicated(fivedtlibs_identifiers$DrugID_ChEMBL),]

#Scrub drug names.
fivedtlibs_identifiers$DrugName = gsub('.*insulin human.*', 'Regular human insulin', fivedtlibs_identifiers$DrugName)
fivedtlibs_identifiers$DrugName = gsub('.*insulin pork.*', 'insulin (bovine)', fivedtlibs_identifiers$DrugName)

rm(lib)
```

```{r fivedtlibs_get_PCID, eval = TRUE}
PCID_fname = 'synonyms/fivedtlibs_PCIDs.txt'
if(file.exists(PCID_fname)){
  PCID_table = read_table(PCID_fname)
  PCIDs = PCID_table$PCID
} else {
  #Get PCIDs.
  
  PCID_ChEMBL_only_fname = 'synonyms/fivedtlibs_PCIDs_ChEMBL_ID_only.txt'
  if(file.exists(PCID_ChEMBL_only_fname)){
    PCID_table = read_table(PCID_ChEMBL_only_fname)
    PCIDs = PCID_table$PCID
  } else {
    PCIDs = do_chunkwise(get_cid, fivedtlibs_identifiers$DrugID_ChEMBL, 
                       out_fname = PCID_ChEMBL_only_fname,
                       DELETE_OUTFILE = FALSE,
                       first = TRUE)
    PCID_table = data.frame(DrugID_ChEMBL = fivedtlibs_identifiers$DrugID_ChEMBL, PCID = PCIDs)
    write_table(PCID_table, fname = PCID_ChEMBL_only_fname)
  }

  #For the NA results, try again with the DrugName, the DrugBank ID, and then the SMILES.
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, fivedtlibs_identifiers[is.na(PCIDs),'DrugName'], first = TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, fivedtlibs_identifiers[is.na(PCIDs),'DrugID_DrugBank'], first = TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, fivedtlibs_identifiers[is.na(PCIDs),'DrugID_SMILES'], first = TRUE)
  #Finally, try with cleaned drug names.
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, clean_drug_names(fivedtlibs_identifiers[is.na(PCIDs),'DrugName']), first=TRUE)
  
  PCID_table = data.frame(DrugID_ChEMBL = fivedtlibs_identifiers$DrugID_ChEMBL, PCID = PCIDs)
  write_table(PCID_table, fname = PCID_fname)
  rm(PCID_ChEMBL_only_fname, PCID_table)
}
rm(PCID_fname)

names(PCIDs) = fivedtlibs_identifiers$DrugID_ChEMBL
fivedtlibs_identifiers$DrugID_PC = PCIDs
write_table(fivedtlibs_identifiers, fname='synonyms/fivedtlibs_identifiers.csv')
```

`r sum(is.na(PCIDs))` out of `r length(PCIDs)` PCIDs were unable to be converted.

Next, for each library, I added a column of the PCIDs, and checked for compounds which have different ChEMBL IDs but were assigned the same PubChem ID.

```{r fivedtlibs_rename_to_PCID, eval = TRUE}
for(i in 1:length(fivedtlibs_fnames)){
  lib_fname = fivedtlibs_fnames[[i]]
  lib = fread(lib_fname)
  lib$DrugID_PC = clean_drug_names(PCIDs[tolower(lib$DrugID_ChEMBL)])
  #Use the PubChem ID, or the common name if the PubChem ID is unavailable.
  lib$gvm = ifelse(!is.na(lib$DrugID_PC), paste0('pc', lib$DrugID_PC), clean_drug_names(lib$DrugName))
  
  #Check for compounds with different ChEMBL IDs but the same PubChem ID.
  subset = lib[!duplicated(lib$DrugID_ChEMBL),]
  subset = subset[!is.na(subset$DrugID_PC),]
  multimapped = subset$DrugID_PC[duplicated(subset$DrugID_PC)]
  multimapped_rows = lib[lib$DrugID_PC %in% multimapped, c('DrugName', 'DrugID_ChEMBL','DrugID_PC')]
  multimapped_rows = unique(multimapped_rows[order(multimapped_rows$DrugID_PC)])
  if(nrow(multimapped_rows)>1){
    knitr::kable(multimapped_rows, caption=fivedtlibs_libnames[[i]], 'html') %>% kable_styling()
  }
  
  write_table(lib, fname=gsub('original_drug-gene_libs','intermediate_files', 
                             gsub('.csv','_PCIDs.csv', lib_fname)))
}
rm(lib, multimapped, multimapped_rows, subset, i, lib_fname)
```

This issue only occured in the Drug-Gene Interaction database. Here, Su-014813 is identical to su-14813. Pergolide is administered as a mesylate salt. Me-344 is a metabolite of nv-128. Enoxaparin and heparin are similar: enoxaparin is often called "low-molecular-weight heparin." I decided to allow these compounds to be equated. 

Now that I have the PubChem IDs, I transformed the libraries into gene vector matrices and used the PubChem IDs (or the ChEMBL ID if the PubChem ID was not found) as the column annotation names. 

```{r}
system('python convert_files.py fivedtlibs')
```

```{r}
rm(PCIDs, PCID_table, fivedtlibs_fnames, fivedtlibs_identifiers, fivedtlibs_libnames)
```

#### STITCH

The chemical names are given as PubChem CIDs, so I kept them as is.

The proteins are given as ENSP IDs, so I converted as many as possible to HGNC format using the biomaRt R package. 

```{r eval = TRUE}
STITCH = fread('original_drug-gene_libs/9606.protein_chemical.links.v5.0.tsv', showProgress = FALSE)

#Ignore the distinction between single and multiple compounds.
STITCH$chemical = gsub('CIDs','pc',STITCH$chemical)
STITCH$chemical = gsub('CIDm','pc',STITCH$chemical)

gene_symbol_lookup_fname = 'synonyms/ENSP_to_HGNC.csv'
if(file.exists(gene_symbol_lookup_fname)){
  gene_symbol_lookup = fread(gene_symbol_lookup_fname)
} else {
  ensembl = useMart('ENSEMBL_MART_ENSEMBL',dataset='hsapiens_gene_ensembl')
  gene_symbol_lookup = getBM(filters= "ensembl_peptide_id", 
                             attributes= c("ensembl_peptide_id","hgnc_symbol"),
                             values=unique(STITCH$protein),
                             mart=ensembl) 
  #Replace blank symbol values with the ENSP.
  gene_symbol_lookup[gene_symbol_lookup$hgnc_symbol=='','hgnc_symbol'] =
    gene_symbol_lookup[gene_symbol_lookup$hgnc_symbol=='','ensembl_peptide_id']
  write.table(gene_symbol_lookup, file=gene_symbol_lookup_fname, row.names=FALSE, quote=FALSE)
}

STITCH$protein = gsub('9606.','',STITCH$protein)
STITCH$protein_symbol = gene_symbol_lookup$hgnc_symbol[match(
  STITCH$protein, gene_symbol_lookup$ensembl_peptide_id)]
```

`r sum(grepl('ENSP', gene_symbol_lookup$hgnc_symbol))` out of `r nrow(gene_symbol_lookup)` ENSP IDs were unable to be converted.

Drug-protein interactions are given a score from 150 to 1000, with higher numbers indicating higher probability of intereaction. Here is a table with the number of protein interactions per drug, with different cutoff levels.

```{r eval = TRUE}
cutoffs = c(300,400,500,600,700,800,900)
info = vector(mode='list',length=length(cutoffs))
for(i in 1:length(cutoffs)){
  s = STITCH[combined_score>cutoffs[i],]
  info[[i]] = c(nrow(unique(s[,'chemical'])), nrow(s)/nrow(unique(s[,'chemical'])))
}

info = as.data.frame(do.call(rbind, info))
info = cbind(cutoffs, info)
colnames(info) = c('Combined score cutoff', 'Number of unique chemicals','Average number of protein interactions per chemical')

kable_styling(kable(info, 'html'))

rm(STITCH, gene_symbol_lookup, gene_symbol_lookup_fname, info, s, cutoffs)
```

I made gmts and gvms for cutoff levels 500, 600, 700 and 800. To be consistent with the five previous libraries, I only kept chemicals with at least five interactions afer applying the cutoff. I also made gmts and gvms with proteins whose ENSP ID could not be converted to a HGNC name removed. These are what I will use for enrichment analysis.

```{r}
system('python convert_files.py STITCH')
```

```{r eval=FALSE}
#I MOVED THIS TO get_gvm.py
cutoffs = c(500,600,700,800)
old_gvm_fnames = paste0('original_drug-gene_libs/STITCH_', cutoffs, 'Cutoff_gvm.csv')
for(gvm_fname in old_gvm_fnames){
  new_gvm_fname = gsub('_gvm.csv', '_noENSP_gvm.csv', gvm_fname)
  if(file.exists(new_gvm_fname)){next}
  gvm = fread(gvm_fname)
  gene.names = unlist(gvm[, 1])
  gvm = gvm[!grepl('ENSP', gene.names),]
  write_gvm(gvm, file=new_gvm_fname)
}
```

#### Drug Target Commons

This library has many interactions. I filtered on the following columns:

* `wildtype_or_mutant`: removing interactions for mutated cell lines.
* `activity_comments`: only keeping interactions with comments that confirmed activity, or which I was unsure how to interpret. This means I removed interactions with negative or inconclusive activity, or which were blank. Tables for activity comments before and after filtering are below.

This library is actually a protein-drug interaction database, so I also converted the UniProt protein IDs to HGNC symbols using the UniProt.ws R package. I removed interactions for which the protein ID could not be converted.

```{r}
DTCommons_intermediate.fname = 'intermediate_files/DTCommons_intermediate.txt'
if(!file.exists(DTCommons_intermediate.fname)){
  DTCommons = fread('original_drug-gene_libs/DtcDrugTargetInteractions.csv')
  
  DTCommons = subset(DTCommons, wildtype_or_mutant!='mutated')
  
  DTCommons$activity_comment = tolower(DTCommons$activity_comment)
  DTCommons$activity_comment = gsub(' \\[.*\\]','',DTCommons$activity_comment)
  DTCommons$activity_comment = gsub('cytochrome p450 mechanistic inhibitor: pmid.*$',
                              'cytochrome p450 mechanistic inhibitor',
                              DTCommons$activity_comment)
  activity_comments = as.data.frame(table(DTCommons$activity_comment))
  activity_comments = activity_comments[rev(order(activity_comments$Freq)),]
  kable_styling(kable(activity_comments[1:12,], 'html', caption='Top 12 activity comments'))
  
  no_activity = '^no inhibition$|^not active$|not active \\(inhibition|^inactive$|ineffective|is not a|no action|no activity|no activity detected|no binding|no block|no change|no detectable activity|no displacement|no effect|no enzyme activity|no evidence for binding|no inactivation|no incorporation|no increase|no inhibitory action|no interactions|no loss in activity|no measureable reactivation observed|no reaction|no reactivation|no significant|no substrate detected|no time-dependent inhibition|^none$|none observed|not a substrate|phenotype: inactive'
  
  uncertain = 'compound not obtained|could not be accurately determined due to low solubility|inconclusive|not determined|not estimated accurately|not evaluated|not examined|not measureable|unstable|unable to be measured|the compound was too insoluble to obtain reliable data|not detectable|not detected|non valid test|unspecified|no data'
  
  DTCommons=DTCommons[!grepl(no_activity, DTCommons$activity_comment),]
  DTCommons=DTCommons[!grepl(uncertain, DTCommons$activity_comment),]
  DTCommons=DTCommons[nzchar(DTCommons$activity_comment),]
  
  activity_comments = as.data.frame(table(DTCommons$activity_comment))
  activity_comments = activity_comments[rev(order(activity_comments$Freq)),]
  kable_styling(kable(activity_comments[1:12,], 'html', caption='Top 12 activity comments, after filtering'))
  
  up = UniProt.ws(taxId=9606)
  unique_target_ids = unique(DTCommons$target_id)
  uniprot_to_hgnc = select(up, keys=unique_target_ids, columns='GENES', keytype='UNIPROTKB')
  uniprot_to_hgnc$GENES = gsub('\\s+', '|', gsub('[^[:alnum:]]',' ', uniprot_to_hgnc$GENES))
  uniprot_to_hgnc$GENES[is.na(uniprot_to_hgnc$GENES)] = ''
  
  DTCommons$gene_names = gsub('\\s+', '|', gsub('[^[:alnum:]]',' ', DTCommons$gene_names))
  DTCommons$gene_names[DTCommons$gene_names==''] = uniprot_to_hgnc$GENES[match(DTCommons$target_id[DTCommons$gene_names==''],
                                                                   uniprot_to_hgnc$UNIPROTKB)]
  DTCommons$gene_names = toupper(DTCommons$gene_names)
  DTCommons = subset(DTCommons, gene_names != '')
  write.table(DTCommons, file=DTCommons_intermediate.fname, sep='\t', quote=FALSE, row.names=FALSE)  
}
DTCommons = fread(DTCommons_intermediate.fname, sep='\t')
```

```{r}
DTCommons=DTCommons[,c('compound_id','standard_inchi_key','compound_name','gene_names')]
DTCommons$compound_id = tolower(DTCommons$compound_id)
DTCommons$compound_name = tolower(DTCommons$compound_name)
DTCommons = unique(DTCommons)
```

Next, I tried to obtain the PubChem IDs by using, in this order:

* the ChEMBL ID
* the Standard InChIKey
* the compound name
* the cleaned compound name (alphanumeric characters only)

```{r}
PCID_fname = 'synonyms/DTCommons_PCIDs.txt'
if(file.exists(PCID_fname)){
  PCIDs = read.table(PCID_fname, sep='\t', quote='', 
                     header = FALSE, comment.char = "")
  PCIDs = PCIDs[,2]
  
  PCIDs = PCIDs[match(DTCommons$compound_id, unique(DTCommons$compound_id))]
  PCIDs = as.numeric(PCIDs)
} else {
  DTCommons_identifiers = unique(DTCommons[,-c('gene_names')])
  
  fivedtlibs_identifiers = fread('synonyms/fivedtlibs_identifiers.csv')
  PCIDs = fivedtlibs_identifiers$DrugID_PC[match(DTCommons_identifiers$compound_id, 
                                                 fivedtlibs_identifiers$DrugID_ChEMBL)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(DTCommons_identifiers$compound_name[is.na(PCIDs)], 
                                                     fivedtlibs_identifiers$DrugName)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(clean_drug_identifiers(DTCommons_identifiers$compound_name[is.na(PCIDs)]), 
                                                     fivedtlibs_identifiers$DrugName)]
  
  old_DTCommons_PCIDs_fname = 'synonyms/DTCommons_PCIDs_OLD.txt'
  if(file.exists(old_DTCommons_PCIDs_fname)){
    old_PCIDs = fread(old_DTCommons_PCIDs_fname)
    colnames(old_PCIDs) = c('chembl_id','pc_id')
    old_PCIDs$chembl_id = tolower(old_PCIDs$chembl_id)
    PCIDs[is.na(PCIDs)] = old_PCIDs$pc_id[match(DTCommons_identifiers$compound_id[is.na(PCIDs)], old_PCIDs$chembl_id)]
  }
  
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, DTCommons_identifiers$compound_id[is.na(PCIDs)],
                                     out_fname = 'synonyms/DTCommons_temp1.txt', from='name', first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, DTCommons_identifiers$standard_inchi_key[is.na(PCIDs)],
                                     out_fname = 'synonyms/DTCommons_temp2.txt', from='inchikey', first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, clean_drug_names(DTCommons_identifiers$compound_id[is.na(PCIDs)]),
                                     out_fname = 'synonyms/DTCommons_temp3.txt', from='name', first=TRUE)

  PCIDs = PCIDs[match(DTCommons$compound_id, unique(DTCommons$compound_id))]
  PCIDs = as.numeric(PCIDs)
  
  PCID_table = unique(as.data.frame(cbind(DTCommons$compound_id, PCIDs)))
  
  write.table(PCID_table, file = PCID_fname, sep = '\t', quote = FALSE,
                col.names = FALSE, row.names = FALSE)
  
  names(PCIDs) = DTCommons$compound_id
  
  rm(PCID_table, fivedtlibs_identifiers, DTCommons_identifiers, old_PCIDs, old_DTCommons_PCIDs_fname, unique_chembl_ids)
}
```

I was not able to convert ```r length(unique(names(PCIDs)[is.na(PCIDs)]))``` out of ```r length(unique(names(PCIDs)))``` genes.

```{r}
rm(activity_comments, uniprot_to_hgnc, up, no_activity, uncertain, PCID_fname, unique_target_ids)
```

For the final gvm name I used the PCID, and the drug name if that is unavailable, and the ChEMBL ID if both are unavailable.

```{r}
DTCommons$pc_id = PCIDs
DTCommons$gvm = ifelse(is.na(PCIDs),
                   ifelse(DTCommons$compound_name == '', 
                          clean_drug_names(DTCommons$compound_id), 
                          clean_drug_names(DTCommons$compound_name)),
                   paste0('pc', PCIDs))

genes = strsplit(DTCommons$gene_names, split = '\\|')
DTCommons = data.frame(compound_id = rep(DTCommons$compound_id, sapply(genes, length)),
                 standard_inchi_key = rep(DTCommons$standard_inchi_key, sapply(genes, length)),
                 compound_name = rep(DTCommons$compound_name, sapply(genes, length)),
                 gene_name = unlist(genes),
                 pc_id = rep(DTCommons$pc_id, sapply(genes, length)),
                 gvm = rep(DTCommons$gvm, sapply(genes, length)))

write_table(DTCommons, fname='intermediate_files/DTCommons_interactionlist.txt')
rm(PCIDs)
```

```{r}
system('python convert_files.py DTCommons')
```

#### CREEDS and the LINCS 1000

Each drug perturbation signature library was originally two separate gmt files: one for the up-perturbed genes, and one for the down-perturbed genes. I first merged these files by taking the union of up-perturbed and down-perturbed genes for each sample. I then converted this to a gene vector matrix with each sample as its own column.

```{r drug_pert_sig_get_gvms}
#Obtain all libraries as gene vector matrix files.
system('python convert_files.py pertlibs')
```

The next step was to obtain the PubChem IDs.

*CREEDS*: In CREEDS, each sample is described by both a name and a DrugBank ID. In addition, some names contain a symnonym in parentheses. I began by extracting and scrubbing the drug name and DrugBank ID. I then removed embedded synonyms from the drug name.

```{r CREEDS_clean_sample_name}
CREEDS.annotations.fname = 'intermediate_files/CREEDS_original_annotations.csv'
#Extract drug names and the DrugBank IDs. 
CREEDS.samples = fread(CREEDS.annotations.fname, sep='\n', showProgress=FALSE)$annotations
CREEDS.drugs = CREEDS.samples
CREEDS.DB_ID = vector(mode='character', length=length(CREEDS.drugs))
for(i in 1:length(CREEDS.drugs)){
  CREEDS.drugs[i] = strsplit(CREEDS.drugs[[i]], ' GSE')[[1]][1] %>% strsplit(split=' ')
  CREEDS.DB_ID[i] = tail(CREEDS.drugs[[i]], 2)[1]
  CREEDS.drugs[i] = paste(head(CREEDS.drugs[[i]], -2), collapse=' ')
}
CREEDS.drugs = tolower(as.character(CREEDS.drugs))
CREEDS.DB_ID = tolower(as.character(CREEDS.DB_ID))

CREEDS.drugs = gsub(' effect on .*','',CREEDS.drugs)
CREEDS.drugs = gsub(' compound sid.*','',CREEDS.drugs)
CREEDS.drugs = gsub(' regular','',CREEDS.drugs)
CREEDS.drugs = gsub(',.*ec50.*','',CREEDS.drugs)
CREEDS.drugs = gsub(' cid.*','',CREEDS.drugs)
CREEDS.drugs = gsub(' \\(.*h\\)','', CREEDS.drugs)

#Scrub DB IDs.
CREEDS.DB_ID = replace(CREEDS.DB_ID, CREEDS.DB_ID=='na', '')
CREEDS.DB_ID[(!grepl('db', CREEDS.DB_ID))&(!CREEDS.DB_ID=='')] = paste0('db',
  CREEDS.DB_ID[(!grepl('db', CREEDS.DB_ID))&(!CREEDS.DB_ID=='')])

#Remove embedded synonyms.
embedded = extract_embedded_synonyms(CREEDS.drugs)
CREEDS.drugs = embedded[[1]]
CREEDS.synonyms = embedded[[2]]

#Create a table with all the names.
CREEDS_identifiers = as.data.frame(cbind(CREEDS.samples, CREEDS.drugs, CREEDS.DB_ID, rep(NA, length=length(CREEDS.drugs))))
colnames(CREEDS_identifiers) = c('sample','drug','dbID','syn')
CREEDS_identifiers$syn = as.character(CREEDS_identifiers$syn)
CREEDS_identifiers$syn[match(CREEDS.synonyms[,1], CREEDS.drugs)] = CREEDS.synonyms[,2]
rm(CREEDS.drugs, CREEDS.synonyms, CREEDS.DB_ID, embedded, drug, i)
```

I tried to obtain the PubChem IDs first by using the following information, in this order:

* the Drug Name
* the DrugBank ID
* the synonym, if any
* the cleaned Drug Name
* the cleaned synonym, if any

```{r}
CREEDS.PCID_file = 'synonyms/CREEDS_PCIDs.csv'
if(!file.exists(CREEDS.PCID_file)){
  drug_name = CREEDS_identifiers$drug
  drug_name.cleaned = clean_drug_names(CREEDS_identifiers$drug)
  dbID = CREEDS_identifiers$dbID
  synonym = CREEDS_identifiers$syn
  synonym.cleaned = clean_drug_names(CREEDS_identifiers$syn)
  
  fivedtlibs_identifiers = fread('synonyms/fivedtlibs_identifiers.csv')
  PCIDs = fivedtlibs_identifiers$DrugID_PC[match(drug_name, 
                                                 fivedtlibs_identifiers$DrugName)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(dbID[is.na(PCIDs)], 
                                                     fivedtlibs_identifiers$DrugID_DrugBank)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(synonym[is.na(PCIDs)], 
                                                     fivedtlibs_identifiers$DrugName)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(drug_name.cleaned[is.na(PCIDs)], 
                                                     fivedtlibs_identifiers$DrugName)]
  PCIDs[is.na(PCIDs)] = fivedtlibs_identifiers$DrugID_PC[match(synonym.cleaned[is.na(PCIDs)], 
                                                     fivedtlibs_identifiers$DrugName)]
  
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, drug_name[is.na(PCIDs)],
                                     out_fname = 'synonyms/CREEDS_temp1.txt', 
                                     CHUNKSIZE = 1000, first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, dbID[is.na(PCIDs)], 
                                     out_fname = 'synonyms/CREEDS_temp2.txt', 
                                     CHUNKSIZE = 1000, first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, synonym[is.na(PCIDs)], 
                                     out_fname = 'synonyms/CREEDS_temp3.txt', 
                                     CHUNKSIZE = 1000, first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, drug_name.cleaned[is.na(PCIDs)], 
                                     out_fname = 'synonyms/CREEDS_temp4.txt', 
                                     CHUNKSIZE = 1000, first=TRUE)
  PCIDs[is.na(PCIDs)] = do_chunkwise(get_cid, synonym.cleaned[is.na(PCIDs)], 
                                     out_fname = 'synonyms/CREEDS_temp5.txt', 
                                     CHUNKSIZE = 1000, first=TRUE)
  
  write_table(data.frame(DrugID_ChEMBL = drug_name, PCID = PCIDs), fname=CREEDS.PCID_file, na='')
  rm(drug_name, drug_name.cleaned, synonym, dbID, synonym.cleaned)
}
PCIDs = read_table(CREEDS.PCID_file)
PCIDs = PCIDs$PCID
CREEDS_identifiers$PCID = PCIDs
CREEDS_identifiers$gvm = ifelse(!is.na(CREEDS_identifiers$PCID), 
                              paste0('pc', CREEDS_identifiers$PCID), 
                              clean_drug_names(CREEDS_identifiers$drug))
```

```{r eval=TRUE}
CREEDS_unique = unique(colnames(fread('gvms/CREEDS_gvm.csv', showProgress = FALSE))[-1])
CREEDS_noPCID = CREEDS_unique[!grepl('pc', CREEDS_unique)]
```

Out of `r length(CREEDS_unique)` unique drugs, I was unable to obtain  `length(CREEDS_noPCID) ` PCIDs. 

```{r replace_CREEDS_names}
CREEDS.old = fread('intermediate_files/CREEDS_noPCIDs_gvm.csv')
CREEDS_fname = 'gvms/CREEDS_gvm.csv'
if(!file.exists(CREEDS_fname)){
  colnames(CREEDS.old)[1] = 'CREEDS'
  colnames(CREEDS.old)[-1] = CREEDS_identifiers$gvm
  CREEDS.old[CREEDS.old=='TRUE'] = 'True'
  write_gvm(CREEDS.old, fname = CREEDS_fname)
}
write_table(CREEDS_identifiers, fname='synonyms/CREEDS_identifiers.csv', na='')
rm(list = setdiff(ls(), lsf.str()))
```

*LINCS*: I extracted the drug names from the sample names. I then added and removed embedded synonyms.

```{r, results='hide'}
LINCS.annotations.fname = 'intermediate_files/LINCS_original_annotations.csv'
#Extract drug names and the DrugBank IDs. 
LINCS.samples = fread(LINCS.annotations.fname, sep='\n')$annotations
#Extract drug name.
LINCS.drugs = strsplit(LINCS.samples, split='-')
for(i in 1:length(LINCS.drugs)){
  sample = LINCS.drugs[[i]]
  drug = do.call(paste, as.list(sample[2:(length(sample) - 1)]))
  LINCS.drugs[[i]] = drug
}
LINCS.drugs = tolower(as.character(LINCS.drugs))

#For the drug name "_(2-aminoethyl)-4-chlorobenzamide_(ro-16-6491)", the first "_(" is not a synonym. So prevent it from being added and manually add ('(2-aminoethyl)-4-chlorobenzamide', 'ro-16-6491').
#The list is still imperfect but I will move forward with it.
paren_results = extract_embedded_synonyms(LINCS.drugs, 
  left_paren_split = '_\\(', no_syns_substrs = c('_\\(2-amino'))
LINCS.drugs = paren_results[[1]]
LINCS.synonyms = paren_results[[2]]
LINCS.synonyms = rbind(LINCS.synonyms, 
                      matrix(c('(2-aminoethyl)-4-chlorobenzamide', 'ro-16-6491'), nrow=1))

LINCS.drugs = gsub('_',' ', LINCS.drugs)

LINCS_identifiers = data.table(sample = LINCS.samples, drug = LINCS.drugs)

fivedtlibs_identifiers = fread('synonyms/fivedtlibs_identifiers.csv')
LINCS_identifiers$PCIDs = fivedtlibs_identifiers$DrugID_PC[match(
  LINCS_identifiers$drug, fivedtlibs_identifiers$DrugName)]
LINCS_identifiers$PCIDs = fivedtlibs_identifiers$DrugID_PC[match(
  clean_drug_names(LINCS_identifiers$drug), 
  clean_drug_names(fivedtlibs_identifiers$DrugName))]
LINCS_identifiers$PCIDs = as.integer(LINCS_identifiers$PCIDs)
```

I tried to obtain the PubChem IDs first by using the following information, in this order:

* the Drug Name
* the synonym, if any
* the cleaned Drug Name
* the cleaned synonym, if any

```{r}
LINCS_identifiers_unique = unique(LINCS_identifiers[,c('drug','PCIDs')])
```

```{r}
LINCS_identifiers_unique$PCIDs[is.na(LINCS_identifiers_unique$PCIDs)] = do_chunkwise(get_cid, LINCS.drugs[is.na(LINCS_identifiers_unique$PCIDs)], out_fname ='synonyms/LINCS_PCIDs1.txt', DELETE_OUTFILE = FALSE, from='name', first=TRUE)
LINCS_identifiers_unique$PCIDs = as.integer(LINCS_identifiers_unique$PCIDs)

LINCS_identifiers_unique$PCIDs[is.na(LINCS_identifiers_unique$PCIDs)] = do_chunkwise(get_cid,  clean_drug_names(LINCS.drugs[is.na(LINCS_identifiers_unique$PCIDs)]), out_fname ='synonyms/LINCS_PCIDs2.txt', DELETE_OUTFILE = FALSE, from='name', first=TRUE)
LINCS_identifiers_unique$PCIDs = as.integer(LINCS_identifiers_unique$PCIDs)

LINCS.syns.query = LINCS.synonyms[,2]

LINCS.syns.query.PCIDs = do_chunkwise(get_cid, LINCS.syns.query, out_fname ='synonyms/LINCS_PCIDs3.txt', from='name', first=TRUE)

LINCS.syns.query.PCIDs[is.na(LINCS.syns.query.PCIDs)] = do_chunkwise(get_cid, clean_drug_names(LINCS.syns.query[is.na(LINCS.syns.query.PCIDs)]), out_fname ='synonyms/LINCS_PCIDs4.txt', from='name', first=TRUE)

LINCS_identifiers_unique$PCIDs[is.na(LINCS_identifiers_unique$PCIDs)] = LINCS.syns.query.PCIDs[match(LINCS_identifiers_unique$syn, LINCS.syns.query)][is.na(LINCS_identifiers_unique$PCIDs)]
```

```{r}
LINCS_identifiers$syn = LINCS.synonyms[,2][match(LINCS_identifiers$drug,
                                               LINCS.synonyms[,1])]

LINCS_identifiers$PCIDs = LINCS_identifiers_unique$PCIDs[match(LINCS_identifiers$drug, LINCS_identifiers_unique$drug)]

LINCS_identifiers$gvm = ifelse(is.na(LINCS_identifiers$PCIDs),
                             clean_drug_names(LINCS_identifiers$drug),
                             paste0('pc', LINCS_identifiers$PCIDs))

write_table(LINCS_identifiers, 'synonyms/LINCS_identifiers.csv', na='')
```

```{r eval=TRUE}
LINCS_identifiers = read_table('synonyms/LINCS_identifiers.csv')
```

Out of `r length(LINCS_identifiers$PCIDs)` unique drugs, I was unable to obtain `r sum(is.na(LINCS_identifiers$PCIDs))` PCIDs. 

```{r replace_LINCS_names}
#LINCS was too big to save as a csv--it is a pickled pandas DataFrame file.
#I wrote the script to rename it in Python.
system('python convert_files.py LINCS2')
```

```{r}
rm(list = setdiff(ls(), lsf.str()))
```

# Summary

Here is a table summarizing each drug library.

```{r table_1, eval=TRUE}
t1 = read.csv('intermediate_files/lib_summary_table.csv', sep='\t')
t1 = as.data.frame(t1)
links = t1$link
t1 = t1[-match('link', names(t1))]
colnames(t1) = c('Name', 'Library Type', 'Description','Number of samples', 'Number of unique drugs', 'Average number of genes per annotation', 'Data preprocessing')

t1[,'Name'] = paste0("[", as.character(t1[,'Name']), "](http://", links, ")")

kable(t1, 'html', caption='Table 1: Dataset summary') %>%
  kable_styling(bootstrap_options=c('striped', 'condensed', full_width=F, font_size=10))

```

Here are the number of unique matching drugs between each pair of libraries.

```{r eval=TRUE}
t1 = read.csv('intermediate_files/lib_summary_matches.csv', sep='\t')
t1 = as.data.frame(t1)
rownames(t1) = colnames(t1)
kable_styling(kable(t1, 'html', caption='Number of matches'))
```

#### Expansion with coexpression or PPI data

From the "average number of genes per sample" column in Table 1, it is apparent that the average gene set sizes for the drug target libraries (DrugBank, TargetCentral, DGIdb, DrugRepHub, DrugCentral, DTCommons, and STITCH) are too small for enrichment analysis. These libraries were expanded using data from three sources: ARCHS4 (a coexpression database), hu.MAP, and BioGRID (both PPI databases). 

To do this, gene coexpression/interaction sets were extracted from each library by taking the top 100 coexpressed/interacting genes/proteins for each gene/protein. (For BioGRID, since interaction scores are not provided, the first 100 entries for each gene/protein, from top to bottom in the original file, were kept.) Then, each gene set in the drug libraries is expanded by adding to it the coexpression set of each gene/protein it contains. For example, the gene set {CTPS, MLLT11} becomes the union of: (1) {CTPS, MLLT11}, (2) the coexpression set for CTPS, and (3) the coexpression set for MLLT11. (If a gene does not appear in the expansion library, the coexpression set is interpreted as just the gene itself.) The result is three new drug target libraries for each original drug target library: one for each expansion library.

```{r get_top_n_for_ppi_libs, results='hide'}
source('expand_gvms.R')
ppi.coexp_files = c('ppi-coexp_libs\\human_correlation.rda', 
                    'ppi-coexp_libs\\mouse_correlation.rda',
                    'ppi-coexp_libs\\genename_pairsWprob.txt',
                    'ppi-coexp_libs\\BIOGRID-ORGANISM-Homo_sapiens-3.4.160.tab2.txt')
output_files = c('ppi-coexp_libs\\ARCHS4_human.csv', 'ppi-coexp_libs\\ARCHS4_mouse.csv', 
                 'ppi-coexp_libs\\huMAP.csv', 'ppi-coexp_libs\\BioGRID.csv')
lapply(ppi.coexp_files, get_top_n_coexpressed, output_files)
```

```{r expand_gvms, results='hide'}
system('python convert_files.py expansion_libs')
```

## Enrichment analysis

After creating the expanded libraries, I performed enrichment analysis, using the Fisher's exact test, between each drug target library and perturbation signature library pair.

See https://github.com/MaayanLab/Enrichment_Sandbox for an explanation of how enrichment analysis is used to measure the agreement between different gene set libraries, and how to interpret the bridge plots.

(Still working on obtaining the results.)